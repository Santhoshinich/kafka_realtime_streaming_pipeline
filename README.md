# Real-Time Earthquake Streaming with Kafka & Spark

This project demonstrates a real-time data pipeline using **Apache Kafka** and **Apache Spark Structured Streaming** to ingest, process, and store live earthquake data.

---

## Architecture Overview

Earthquake API → Kafka Producer → Kafka Topic → Spark Structured Streaming → CSV Output

---

## Tech Stack

- Apache Kafka (KRaft mode)
- Apache Spark 3.5.x (Structured Streaming)
- Python 3
- kafka-python
- WSL (Ubuntu)

---

## Project Structure

```text
realtime-earthquake-spark/
│
├── producer/
│   └── earthquake_producer.py
│
├── spark/
│   └── spark_streaming_job.py
│
├── output/
│   └── csv/                # Generated by Spark
│
├── checkpoint/             # Spark checkpoint directory
│
├── README.md
└── .gitignore
